{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007bb1c0-0edf-4f1b-aeea-1126bb89f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cc7eae-751b-43e9-8ddb-2d4ec146b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_gaussian_quantiles, make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f18df4-3fd7-4481-a32b-000575a14473",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FairLabel: Correcting Bias in Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d32c1-b394-45bf-8253-aef1d039f760",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6674e1a-5c4a-44e4-bf3e-0ca56e249fec",
   "metadata": {},
   "source": [
    "As ML models are becoming of more and more significance in taking various important decisions each day, algorithmic fairness is more crucial than ever. There is plenty of research on algorithmic fairness but most of it is concentrated on algorithmic bias - bias that is not present in the data but added purely by the algorithm. \n",
    "\n",
    "Sociatal bias and historical discrimination both plague the data we base our precious models on, which will therefore make biased predictions. To combat biased data we use preprocessing methods like preferential sampling and disperate impact removal which remove data biases but keep labels intact. It is impossible to manually re-label ground truth labels because of the sheer amount of time it would take and the lack of information about how the decisions were made. That is the purpose of FairLabel - to mitigate label bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47545731-d8b6-40e9-9d05-cffb0d2106cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metrics for Debiasing Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c4b84-ab64-4189-a298-d8c877bab274",
   "metadata": {},
   "source": [
    "In biased data we have a minority group and a majority group and we can see favourable treatment towards the majority group. A biased decision occurs when the decision maker, having the right qualification, makes a wrong classification purely based on which group the subject belongs to. Overall, the probability for a favourable outcome for a member of the minority class is lower:\n",
    "\n",
    "$$P(y=1\\vert p=minority) < P(y=1\\vert p=majority)$$\n",
    "\n",
    "What FairLabel will do is flip $(0\\rightarrow 1)$ for every mistaken label in the minorty class and do the opposite - $(1\\rightarrow 0)$, for the majority class. In the context of flipping, TPR (True Positive Rate) is the fraction of correct flips and FNR(False Negative rate) is the fraction of missed flips. These two metrics are called TFR (True Flip Rate) and MFR (Missed Flip Rate) respectively. There are also many others some of which are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d925ebf-22aa-42c2-860f-b846bcbd661c",
   "metadata": {},
   "source": [
    "Demographic parity: $$P(\\hat{y}\\vert p) = P(\\hat{y})$$\n",
    "\n",
    "Disperate Impact Ratio (DIR): $$\\frac{P(\\hat{y}\\vert p=minority)}{P(\\hat{y}\\vert p=majority)}$$\n",
    "\n",
    "Disperate Impact Difference (DID): $$P(\\hat{y}=1\\vert p=majority) - P(\\hat{y}=1\\vert p=minority)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d4587-9fed-4d16-9749-93c17342db2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FairLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191f331-f3bd-4fbb-b583-09d81eaadf21",
   "metadata": {},
   "source": [
    "Our algorithm consists of 2 sub algorithms - FairMin and FairMaj."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05350283-2302-4bb8-b989-4aa16a4b8452",
   "metadata": {},
   "source": [
    "First of all, how FairMin works:\n",
    "1. Split data into majority and minority groups\n",
    "2. Train a classifier on the majority group\n",
    "3. Get the classsifier's predictions for the minority group\n",
    "4. Flip labels where the classifier has predicted 1 and the \"true\" label is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95fd94-6565-4e25-9dc7-b777433598ab",
   "metadata": {},
   "source": [
    "This way we make sure both classes are being treated equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526551a7-4339-4314-af5a-3afff01acfe4",
   "metadata": {},
   "source": [
    "Next we could apply FairMaj (optionally):\n",
    "1. Split data into majority and majority groups\n",
    "2. Train a classifier on the minority group\n",
    "3. Get the classsifier's predictions for the minority group\n",
    "4. Flip labels where the classifier has predicted 0 and the \"true\" label is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83f639-9ec3-4e55-a48c-c59939765a05",
   "metadata": {},
   "source": [
    "Now we are going to implement it using transformers and then combine it to an ultimate pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e22eb71-9630-47b0-8717-c3bade77853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for FAIRMIN\n",
    "class FAIRMINTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.7, feature_index = 4):\n",
    "        self.threshold = threshold\n",
    "        self.feature_index = feature_index\n",
    "        self.classifier_majority = LogisticRegression(random_state=42)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        indices_majority = np.where(X[self.feature_index] < self.threshold)[0]\n",
    "        X_majority, y_majority = np.array([X[i] for i in indices_majority]), np.array([y[i] for i in indices_majority])\n",
    "        self.classifier_majority.fit(X_majority, y_majority)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        indices_minority = np.where(X[self.feature_index] > self.threshold)[0]\n",
    "        X_minority, y_minority = np.array([X[i] for i in indices_minority]), np.array([y[i] for i in indices_minority])\n",
    "        predictions_minority = self.classifier_majority.predict(X_minority)\n",
    "        flipped_labels_minority = np.where(predictions_minority > self.threshold, 1, 0)\n",
    "        return np.concatenate((X, X_minority)), np.concatenate((y, flipped_labels_minority))\n",
    "\n",
    "# Custom transformer for FAIRMAJ\n",
    "class FAIRMAJTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.7, feature_index = 4):\n",
    "        self.threshold = threshold\n",
    "        self.feature_index = feature_index\n",
    "        self.classifier_minority = LogisticRegression(random_state=42)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        indices_minority = np.where(X[self.feature_index] > self.threshold)[0]\n",
    "        X_minority, y_minority = np.array([X[i] for i in indices_minority]), np.array([y[i] for i in indices_minority])\n",
    "        self.classifier_minority.fit(X_minority, y_minority)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        indices_majority = np.where(X[self.feature_index] < self.threshold)[0]\n",
    "        X_majority, y_majority = np.array([X[i] for i in indices_majority]), np.array([y[i] for i in indices_majority])\n",
    "        predictions_majority = self.classifier_minority.predict(X_majority)\n",
    "        flipped_labels_majority = np.where(predictions_majority > self.threshold, 1, 0)\n",
    "        return np.concatenate((X_majority, X)), np.concatenate((flipped_labels_majority, y))\n",
    "\n",
    "# Concatenate transformer\n",
    "class ConcatenateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return np.concatenate(X, axis=0), np.concatenate(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cb6a3f-5e9a-4e04-9c05-bf701a03dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "fairlabel_pipeline = Pipeline([\n",
    "    ('fairmin', FAIRMINTransformer()),\n",
    "    ('fairmaj', FAIRMAJTransformer()),\n",
    "    ('concatenate', ConcatenateTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a383ab4-25d9-41cf-ab8b-4860e2d69167",
   "metadata": {},
   "source": [
    "## Synthetic datasets for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b053223-7e8a-4c38-91ec-9f6bb63749d0",
   "metadata": {},
   "source": [
    "To test our theory we will do three experiments with three different synthetic datasets:\n",
    "* Linear\n",
    "* Clusters around n-hypercubes\n",
    "* Gaussian Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ef484-4aaf-4f5e-ada6-ed4fd7a9cb30",
   "metadata": {},
   "source": [
    "We will generate the linear dataset with the function below (it inserts noise also into the data, as it should):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52905b5-7ec2-4300-9d66-f3f98cb0bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear_dataset(n_samples, n_features, p_noise, feature_bias_index=None, feature_bias_threshold=0.0):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def generate_random_coefficients(n_features):\n",
    "        return np.random.randn(n_features)\n",
    "\n",
    "    def generate_random_x(n_features, n_samples):\n",
    "        return np.random.randn(n_samples, n_features)\n",
    "\n",
    "    def generate_random_binary(n_samples):\n",
    "        return np.random.choice([0, 1], size=n_samples)\n",
    "    \n",
    "    n_samples_perfect = int(n_samples * (1 - p_noise))\n",
    "    n_samples_noise = n_samples - n_samples_perfect\n",
    "\n",
    "    w = generate_random_coefficients(n_features)\n",
    "    \n",
    "    X = generate_random_x(n_features, n_samples_perfect)\n",
    "    probs = sigmoid(np.dot(X, w))\n",
    "    y = np.array([1 if i > 0.5 else 0 for i in probs]).reshape(n_samples_perfect)\n",
    "\n",
    "    X_noise = generate_random_x(n_features, n_samples_noise)\n",
    "    y_noise = generate_random_binary(n_samples_noise)\n",
    "    \n",
    "    if feature_bias_index is not None:\n",
    "        biased_indices = X_noise[:, feature_bias_index] > feature_bias_threshold\n",
    "        y_noise[biased_indices] = np.round(np.random.rand(len(y_noise[biased_indices])))\n",
    "        \n",
    "    X_full = np.concatenate((X, X_noise))\n",
    "    y_full = np.concatenate((y, y_noise))\n",
    "\n",
    "    return X_full, y_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b3f18-8da1-46fe-b564-79efe0da97af",
   "metadata": {},
   "source": [
    "For the other 2 we are going to use sklearn.datasets to generate the datasets but since the sklearn functions do not have parameters for introducing bias, we are going to have to inject it ourselves with postprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44469f4b-a875-4fe1-821e-57553a0b34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_feature_bias(X, y, feature_index, bias_threshold):\n",
    "    \n",
    "    biased_indices = X[:, feature_index] > bias_threshold\n",
    "    y[biased_indices] = np.round(np.random.rand(len(y[biased_indices])))\n",
    "    return X, y\n",
    "\n",
    "def make_gauss_biased(n_samples, n_features, bias_level):\n",
    "    X, y = make_gaussian_quantiles(n_samples=n_samples, n_features=n_features, n_classes=2, random_state=42)\n",
    "\n",
    "    X_biased, y_biased = introduce_feature_bias(X, y, 4, bias_level)\n",
    "    return X_biased, y_biased\n",
    "    \n",
    "def make_hypercubes_biased(n_samples, n_features, bias_level):\n",
    "    X, y = make_classification(n_samples, n_features, random_state=42)\n",
    "\n",
    "    X_biased, y_biased = introduce_feature_bias(X, y, 4, bias_level)\n",
    "    return X_biased, y_biased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed1e0b-ebe6-4977-a210-4bfff5db559c",
   "metadata": {},
   "source": [
    "Now let's get our datasets ready, splitting them 80/20 for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52efe9ef-67c6-4787-9a40-6f65b041ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lin, y_lin = generate_linear_dataset(2000, 7, 0.5, feature_bias_index=4, feature_bias_threshold=0.7)\n",
    "X_gauss, y_gauss = make_gauss_biased(2000, 7, 0.7)\n",
    "X_hcube, y_hcube = make_hypercubes_biased(2000, 7, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a206353-8381-4042-8b5d-043d3fa95dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lin_train, X_lin_test, y_lin_train, y_lin_test = train_test_split(X_lin, y_lin, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e85367-1735-4c1d-a75e-c6f8b5ece07f",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3e2f0-9d93-4b96-b50f-76fc4cf9d23f",
   "metadata": {},
   "source": [
    "Disclaimer: This is the furthest I got because there seems to be a mistake and I feel lost looking at the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e8098e7-8748-4eaf-86bc-25910dc3e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43448880-b5fd-4bad-b920-d0c9e1a5ece9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.012820</td>\n",
       "      <td>-0.017452</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>-0.083337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>-0.043700</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>-0.020006</td>\n",
       "      <td>-0.017279</td>\n",
       "      <td>-0.047186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012820</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.020588</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.032505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017452</td>\n",
       "      <td>-0.043700</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.018699</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>-0.236125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>-0.020588</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031215</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>-0.159333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012079</td>\n",
       "      <td>-0.020006</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>-0.018699</td>\n",
       "      <td>0.031215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034128</td>\n",
       "      <td>0.156498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016363</td>\n",
       "      <td>-0.017279</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.034128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.083337</td>\n",
       "      <td>-0.047186</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.236125</td>\n",
       "      <td>-0.159333</td>\n",
       "      <td>0.156498</td>\n",
       "      <td>-0.261428</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000 -0.003091 -0.012820 -0.017452  0.012557  0.012079  0.016363   \n",
       "1 -0.003091  1.000000  0.013164 -0.043700  0.019759 -0.020006 -0.017279   \n",
       "2 -0.012820  0.013164  1.000000 -0.000100 -0.020588  0.026882  0.001786   \n",
       "3 -0.017452 -0.043700 -0.000100  1.000000  0.007443 -0.018699  0.016272   \n",
       "4  0.012557  0.019759 -0.020588  0.007443  1.000000  0.031215  0.008602   \n",
       "5  0.012079 -0.020006  0.026882 -0.018699  0.031215  1.000000  0.034128   \n",
       "6  0.016363 -0.017279  0.001786  0.016272  0.008602  0.034128  1.000000   \n",
       "0 -0.083337 -0.047186  0.032505 -0.236125 -0.159333  0.156498 -0.261428   \n",
       "\n",
       "          0  \n",
       "0 -0.083337  \n",
       "1 -0.047186  \n",
       "2  0.032505  \n",
       "3 -0.236125  \n",
       "4 -0.159333  \n",
       "5  0.156498  \n",
       "6 -0.261428  \n",
       "0  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_lin), pd.Series(y_lin)), axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8deb072-9dc8-4ee0-a90e-ae7d01e381b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecec66ca-e435-4bf6-980f-7d5cb0a75491",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transform() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38728\\1676208643.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfairlabel_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_lin_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_lin_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \"\"\"\n\u001b[0;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: transform() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "test1, test2 = fairlabel_pipeline.fit(X_lin_train, y=y_lin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35914c-c230-4cbd-bc80-bf70fa8d0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAIRMINTransformer().fit_transform(X_lin_train, y_lin_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
